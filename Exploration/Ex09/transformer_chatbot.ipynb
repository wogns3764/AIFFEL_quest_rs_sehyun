{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf3dc29",
   "metadata": {},
   "source": [
    "#### project 과정\n",
    "transformer chatbot(한글)\n",
    "- PositionalEncoding: transformer는 병령 처리를 위해 한 번에 입력을 준다 따라서 모델이 순서(맥락)을 알 수 없기 때문에 필요하다\n",
    "- scaled dot product: 차원이 많아질 수록 softmax를 취하면 값의 차이가 극단적으로 나타난다(뽀족해짐) 따라서 차원의 제곱근으로 나눠 그 값의 차이를 평탄화해줘야 한다.\n",
    "- MultiHeadAttention: 차원을 nheads로 나눠서 연산을 한다.\n",
    "- create_look_ahead_mask: 디코더가 예측을 할 때 현재 time보다 나중에 나올말을 보면 안 되기 때문에 mask로 가려주는 역할\n",
    "- 데이터 불러오기 & 간단한 불용어 처리\n",
    "- sentencepiece 모델 학습 (vocab만들기)\n",
    "- 데이터셋 구현\n",
    "- 모델 정의 및 학습하기\n",
    "- 챗봇 테스트하기\n",
    "\n",
    "실험 방법\n",
    "- NUM_LAYERS =2 > 3, DROPOUT: 0.1 > 0.2, warmup_steps=EPOCH*0.1, BATCH_SIZE = 32\n",
    "\n",
    "1. epoch: 50 > 100 > \n",
    "    - 충분한 학습이 이루어지지 못한 것 같다고 생각해서 epoch를 늘려 학습을 다시 실행했을 때 loss는 꾸준히 감소하지만, acc가 0.3XX 이상으로 증가하지 않는 것을 확인하고 epoch를 늘려도 모델의 성능에 영향을 주지 못한 것으로 판단함\n",
    "    - 초반 10~20에포크 acc 업데이트가 안 되었음 | 결과적으로 마지막 테스트에서 의미있는 출력이 나오지 못함\n",
    "    > 코사인 워밍업 방식으로 변경 후 초기 에포크만으로 충분한 학습이 이루어지는 것을 확인됨 \n",
    "\n",
    "2. 전처리 subword(bpe) > subword(unigram)\n",
    "    - 기존 bpe방식은 전체 corpus에서 많이 나온 순서대로 vocab을 만들지만, unigram은 확률적으로 문장에서 가장 정보량이 많은 서브워드 단위로 vocab을 만들기 때문에 변경했다.\n",
    "    > 학습 결과만 보면 acc가 .3xx로 비슷해서 어느 것이 좋다고는 못하겠으나 테스트 결과만 보면 bpe: 1번과 2번 모두 출력이 좋은 좋은 ., unigram: 1번과 2번이 출력이 다른 것을 보면 현재 상황에선 unigram이 조금 더 좋은 것을 판단됨\n",
    "    \n",
    "3. vocab_sise: 8000 > 9000 > 5000 \n",
    "    - vocab_sise를 가능한 최대로 늘렸을 때 이전 보다 출력이 단답이 되는 경우가 발생함. 모델 성능의 개선이 없는 것으 오히려 성능이 저하된 것으로 확인됨\n",
    "\n",
    "3. NUM_LAYERS 수를 2에서 3로 늘리기\n",
    "    - 레이어를 늘림으로 문장의 특징을 좀 더 추출하고자 변경\n",
    "\n",
    "4. oprimizer Adam > AdamW로 변경\n",
    "    - 모델의 과대적합을 방지하기 위해가 가중치 감쇠가 적응형 학습률에 의해 왜곡되지 않고 독립적으로 작동하는 AdamW로 변경했습니다.\n",
    "    > Adam : epoch 30 > Avg Loss: 4.0630, Avg Acc: 0.3868\n",
    "    > AdamW:epoch 30 > Avg Loss: 0.4636, Avg Acc: 0.8826\n",
    "\n",
    "5. 학습률 스케줄러 변경\n",
    "    - 선형 워밍업 > 코사인 어닐링 > 코사인 워밍업 \n",
    "    - 기존 선형 워밍업 방식은 워밍업동안 빠르게 학습률이 높아지고 빠르게 낮아지는 것을 그래프로 학인할 수 있다. 이 과정에서 충분한 학습이 이루어지지 못하는 것으로 생각했다\n",
    "    - 다음으로 코사인어닐링방식을 사용했는데 초기 학습률에서 점진적으로 감소하지만 pre_train에서 과도하게 낮은 학습률은 학습에 방해가 되기 때문에 좋은 성능의 모델을 만들지 못했습니다.\n",
    "    - 다음으로 코사인 워밍업 방식으로 변경했을 때, 기존 선형 워밍업 그래프와 마찬가지로 워밍업동안 학습률이 증가하고 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6df9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcce77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_SAMPLES = 50000                     # 최대 샘플 수 제한\n",
    "file_path = './data/augmented_ChatbotData.csv'    # 파일 경로 설정 \n",
    "corpus_file = \"clean_corpus.txt\"        # sentencepiece corpus 파일\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 4     # 인코더/디코더 층 수\n",
    "D_MODEL = 512     # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8      # 멀티헤드 어텐션에서의 헤드 수\n",
    "UNITS = 2048      # 피드포워드 신경망의 은닉 차원\n",
    "DROPOUT = 0.2      # 드롭아웃 비율\n",
    "VOCAB_SIZE = 7000 # 단어 집합 크기\n",
    "BATCH_SIZE = 32   #배치사이즈\n",
    "EPOCH = 100       # 원하는 에포크\n",
    "lr= 5e-4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8663dd4",
   "metadata": {},
   "source": [
    "---\n",
    "#### 위치 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cde11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncoding 시각화\n",
    "sample_pos_encoding = PositionalEncoding(25, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3728e0c",
   "metadata": {},
   "source": [
    "---\n",
    "#### scaled dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) Q와 K의 내적을 통해 score(유사도) 계산\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul 결과 shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depth에 따라 정규화\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크가 주어졌다면 -1e9(아주 작은 값)를 더해 소프트맥스에서 제외시키도록 함\n",
    "    if mask is not None:\n",
    "        # 텐서플로우: logits += (mask * -1e9)\n",
    "        # 파이토치 동일 적용\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) 소프트맥스 계산해 attention weights 생성\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weights와 value의 내적\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710abed",
   "metadata": {},
   "source": [
    "---\n",
    "#### MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model은 num_heads로 나누어떨어져야 함\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # 파이토치에서 Dense는 nn.Linear로 대응\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) 형태로 변환\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, V에 각각 Linear 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head 분할\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 다시 (batch_size, seq_len, d_model)로 합치기\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 최종 Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd06e4e",
   "metadata": {},
   "source": [
    "---\n",
    "#### masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    # x == 0 위치를 찾아 float형 1로 변환\n",
    "    mask = (x == 0).float()\n",
    "    # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = x.size(1)\n",
    "\n",
    "    # (seq_len, seq_len) 크기의 하삼각 행렬(tril) 생성 후 1에서 빼서\n",
    "    # 상삼각이 1, 하삼각(자기 자신 포함)이 0이 되도록 설정\n",
    "    # => 미래 토큰(자신 인덱스보다 큰 위치) 마스킹\n",
    "    look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "    # 패딩 마스크 생성 (shape: (batch_size, 1, 1, seq_len))\n",
    "    padding_mask = create_padding_mask(x)\n",
    "\n",
    "    # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "    # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "    look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "    look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "    # look-ahead 마스크와 패딩 마스크를 합성 (둘 중 하나라도 1이면 마스킹)\n",
    "    # 최종 shape은 브로드캐스팅으로 (batch_size, 1, seq_len, seq_len)\n",
    "    combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 0, 3, 0],\n",
    "                  [0, 0, 0, 4, 5]])\n",
    "mask = create_padding_mask(x)\n",
    "print(\"입력 텐서 크기 :\", x.shape)    # (2, 5)\n",
    "print(\"생성된 마스크 크기 :\", mask.shape)  # (2, 1, 1, 5)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f324423",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "mask_1 = create_look_ahead_mask(x)\n",
    "print(\"첫 번째 시퀀스:\\n\", mask_1, mask_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aaad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.tensor([[0, 5, 1, 5, 5]])\n",
    "mask_2 = create_look_ahead_mask(x2)\n",
    "print(\"두 번째 시퀀스:\\n\", mask_2, mask_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659ccb4",
   "metadata": {},
   "source": [
    "---\n",
    "#### Encoder&Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d00fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # 이전에 구현한 MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 피드포워드 부분 (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7986c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 임베딩 & sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 적용 + 드롭아웃\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓아올린 EncoderLayer 통과\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 첫 번째 서브 레이어 (디코더 내부 셀프 어텐션)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 두 번째 서브 레이어 (인코더-디코더 어텐션)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 세 번째 서브 레이어 (피드포워드 네트워크)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.ReLU(),                   # activation='relu'\n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # 1) 셀프 어텐션 (디코더 내부)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 2) 인코더-디코더 어텐션\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 3) 피드포워드 (Dense -> ReLU -> Dense)\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb518f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        # 실제 학습 시에는 최대 시퀀스 길이에 맞추어 쓰기도 함\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer 쌓기\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) 임베딩 + sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 + 드롭아웃\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓인 DecoderLayer 통과\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ac8c9",
   "metadata": {},
   "source": [
    "--- \n",
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "\n",
    "    # 구조 확인 (Q, A, label 컬럼이 있는지 확인)\n",
    "    expected_columns = ['Q', 'A', 'label']\n",
    "    if all(col in df.columns for col in expected_columns):\n",
    "        print(\"데이터 로드 성공: 지정된 컬럼(Q, A, label)을 모두 포함하고 있습니다.\")\n",
    "    else:\n",
    "        print(f\"주의: 컬럼 구성이 다릅니다. 현재 컬럼: {list(df.columns)}\")\n",
    "\n",
    "    # 데이터 샘플 확인\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{file_path}' 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c78434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 1. 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 2. 단어와 구두점(?.!,) 사이의 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # 3. 한글(가-힣, ㄱ-ㅎ, ㅏ-ㅣ)과 구두점(?.!,)을 제외한 모든 문자를 공백으로 대체\n",
    "    # 영어도 함께 남기고 싶다면 a-zA-Z를 추가하세요.\n",
    "    sentence = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "    \n",
    "    # 4. 다시 양쪽 공백 제거 및 불필요한 공백 정리\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "# df = df[:MAX_SAMPLES]\n",
    "\n",
    "df['Q'] = df['Q'].apply(preprocess_sentence)\n",
    "df['A'] = df['A'].apply(preprocess_sentence)\n",
    "\n",
    "questions = df['Q'].tolist()\n",
    "answers = df['A'].tolist()\n",
    "pairs = list(zip(questions, answers))\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전처리 후 Q 샘플 :', questions[0])\n",
    "print('전처리 후 A 샘플 :', answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192f7cfb",
   "metadata": {},
   "source": [
    "---\n",
    "#### sentencepiece 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "    for q, a in pairs:\n",
    "        f.write(q + \"\\n\")\n",
    "        f.write(a + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input=corpus_file,\n",
    "    model_prefix=\"spm_uni_cornell\",\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"unigram\",\n",
    "    max_sentence_length=999999,\n",
    "    bos_id=1,  # <s> (Beginning of Sentence) 설정\n",
    "    eos_id=2,  # </s> (End of Sentence) 설정\n",
    "    pad_id=0,  # Padding ID 설정\n",
    "    unk_id=3   # Unknown Token ID 설정\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04379fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('spm_uni_cornell.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 문장\n",
    "sentence = \"12시 땡! 하루가 또 가네요..ㅠㅠ\"\n",
    "\n",
    "sentence = preprocess_sentence(sentence)\n",
    "print(\"전처리 후의 문장:\", sentence)\n",
    "\n",
    "# 1. 토크나이징 (subword 단위로 분할)\n",
    "tokens = sp.encode(sentence, out_type=str)\n",
    "print(\"Tokenized:\", tokens)\n",
    "\n",
    "# 2. 인코딩 (서브워드를 정수 ID로 변환)\n",
    "encoded = sp.encode(sentence, out_type=int)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# 3. 디코딩 (정수 ID → 원본 문장 복원)\n",
    "decoded = sp.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b8c35",
   "metadata": {},
   "source": [
    "데이터셋 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a19dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_plot(df, columns, limit_len=25):\n",
    "    \"\"\"\n",
    "    텍스트 데이터의 길이 통계, 특정 길이 포함 비율 확인 및 시각화를 수행합니다.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    for i, col in enumerate(columns):\n",
    "        # 1. 길이 계산\n",
    "        lengths = df[col].apply(len)\n",
    "        \n",
    "        # 2. 통계치 산출\n",
    "        mean_val = lengths.mean()\n",
    "        median_val = lengths.median()\n",
    "        max_val = lengths.max()\n",
    "        \n",
    "        # 3. 포함 비율 계산 (평균 기준 & 사용자 입력 기준)\n",
    "        mean_coverage = (lengths <= mean_val).sum() / len(lengths) * 100\n",
    "        limit_coverage = (lengths <= limit_len).sum() / len(lengths) * 100\n",
    "        \n",
    "        # 4. 텍스트 통계 출력\n",
    "        print(f\"[{col} 데이터 통계]\")\n",
    "        print(f\" - 평균: {mean_val:.2f} / 중앙값: {median_val} / 최대: {max_val}\")\n",
    "        print(f\" - 평균({mean_val:.2f}) 이하 포함 비율: {mean_coverage:.2f}%\")\n",
    "        print(f\" - 설정 길이({limit_len}) 이하 포함 비율: {limit_coverage:.2f}%\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 5. 히스토그램 시각화\n",
    "        plt.subplot(1, len(columns), i + 1)\n",
    "        plt.hist(lengths, bins=30, alpha=0.7, color='skyblue' if i==0 else 'salmon')\n",
    "        plt.axvline(limit_len, color='red', linestyle='--', label=f'Limit ({limit_len})')\n",
    "        plt.title(f'{col} Length Distribution')\n",
    "        plt.xlabel('Length')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_and_plot(df, columns=['Q', 'A'], limit_len=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb420a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CornellDataset(Dataset):\n",
    "    def __init__(self, pairs, sp, max_length=40):\n",
    "        super().__init__()\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        for q_text, a_text in pairs:\n",
    "            # 1) 토크나이즈\n",
    "            q_ids = sp.EncodeAsIds(q_text)\n",
    "            a_ids = sp.EncodeAsIds(a_text)\n",
    "\n",
    "            # 2) [CLS]/[SEP] 같은 별도 스페셜 토큰을 쓸 수도 있으나,\n",
    "            #    여기서는 SentencePiece 기본 <s>, </s> 등 혹은 사용자 정의 토큰 활용 가능\n",
    "            #    간단히 <s>=sp.bos_id(), </s>=sp.eos_id()로 가정해본다면:\n",
    "            #    sp.SetEncodeExtraOptions(\"bos:eos\") 등으로 설정하는 방법도 있음.\n",
    "            # 여기서는 수동으로 bos/eos id를 붙인다고 가정\n",
    "            bos_id = sp.bos_id() if sp.bos_id() >= 0 else 1  # 혹은 임의값\n",
    "            eos_id = sp.eos_id() if sp.eos_id() >= 0 else 2\n",
    "\n",
    "            q_tokens = [bos_id] + q_ids + [eos_id]\n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            # 3) 길이 제한\n",
    "            if len(q_tokens) > max_length or len(a_tokens) > max_length:\n",
    "                continue\n",
    "\n",
    "            # 4) 고정 길이 패딩\n",
    "            q_tokens += [0]*(max_length - len(q_tokens))  # 0 -> <pad> 가정\n",
    "            a_tokens += [0]*(max_length - len(a_tokens))\n",
    "\n",
    "            # 5) 디코더 입력(dec_input): a_tokens[:-1], 타겟(outputs): a_tokens[1:]\n",
    "            #    (teacher forcing용)\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CornellDataset(pairs, sp, max_length=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoder_input, decoder_input, decoder_label  in dataset:\n",
    "    print(\"텐서 크기 :\",encoder_input.size())\n",
    "    print(encoder_input)\n",
    "    print(sp.decode(encoder_input.tolist()))\n",
    "    print(decoder_input)\n",
    "    print(sp.decode(decoder_input.tolist()))\n",
    "    print(decoder_label)\n",
    "    print(sp.decode(decoder_label.tolist()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f2584",
   "metadata": {},
   "source": [
    " DataLoader 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4133f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoder_input, decoder_input, decoder_label in dataloader:\n",
    "    print(encoder_input.size())\n",
    "    print(decoder_input.size())\n",
    "    print(decoder_label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb901c1",
   "metadata": {},
   "source": [
    "---\n",
    "#### model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # 인코더/디코더 층 수\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 최종 출력층: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # 참고: 텐서플로우 코드의 `name=\"transformer\"`는 파이토치에선 보통 사용 안 함\n",
    "\n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) 인코더 패딩 마스크 생성\n",
    "        enc_padding_mask = create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 look-ahead + 패딩 마스크\n",
    "        look_ahead_mask = create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 쓸 패딩 마스크\n",
    "        dec_padding_mask = create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttention의 가중치 check\n",
    "target_mha = model.encoder.enc_layers[0].mha\n",
    "weight = target_mha.query_dense.weight\n",
    "\n",
    "# 1번 헤드(0~31행)와 2번 헤드(32~63행) 가중치 비교\n",
    "head1_w = weight[:64, :]\n",
    "head2_w = weight[64:128, :]\n",
    "\n",
    "print(\"두 가중치가 같은가? :\", torch.equal(head1_w, head2_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94921446",
   "metadata": {},
   "source": [
    "---\n",
    "#### scheduler 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "TOTAL_STEPS = len(dataloader) * EPOCH\n",
    "WARMUP_STEPS  = int(TOTAL_STEPS * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dd2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Warmup lr\n",
    "noam_lr = lr * math.sqrt(D_MODEL) * math.sqrt(WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noam Scheduler\n",
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        # step은 0부터 시작하므로 +1로 보정\n",
    "        step = step + 1\n",
    "        return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine Warmup\n",
    "def get_cosine_with_warmup_lr_lambda(total_steps, warmup_steps, min_lr_ratio=1e-7):\n",
    "    def lr_lambda(current_step):\n",
    "        # 1. Linear Warmup 구간\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        \n",
    "        # 2. Cosine Annealing 구간\n",
    "        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "        \n",
    "        # cosine_decay는 1.0 ~ min_lr_ratio로 변함\n",
    "        cosine_decay = 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "        \n",
    "        # (1.0 - min_lr_ratio) 범위를 곱해주고 마지막에 min_lr_ratio를 더함\n",
    "        return min_lr_ratio + (1.0 - min_lr_ratio) * cosine_decay\n",
    "        \n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b30409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_history(scheduler, optimizer, total_steps):\n",
    "    history = []\n",
    "    for _ in range(total_steps):\n",
    "        history.append(optimizer.param_groups[0]['lr'])\n",
    "        # 실제 학습 시에는 optimizer.step()이 먼저 호출됨\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return history\n",
    "\n",
    "# 2. 각 케이스별 시뮬레이션\n",
    "# Case 1: LambdaLR (Custom Warmup)\n",
    "model_1 = nn.Linear(D_MODEL, VOCAB_SIZE)\n",
    "opt_1 = optim.AdamW(model_1.parameters(), lr = noam_lr, betas=(0.9, 0.98), weight_decay=0.01)\n",
    "sched_1 = torch.optim.lr_scheduler.LambdaLR(opt_1, lr_lambda=get_lr_lambda(D_MODEL, WARMUP_STEPS))\n",
    "hist_1 = get_lr_history(sched_1, opt_1, TOTAL_STEPS)\n",
    "\n",
    "# Case 2: CosineAnnealingLR\n",
    "model_2 = nn.Linear(D_MODEL, VOCAB_SIZE)\n",
    "opt_2 = optim.AdamW(model_2.parameters(), lr=lr)\n",
    "sched_2 = torch.optim.lr_scheduler.CosineAnnealingLR(opt_2, T_max=TOTAL_STEPS, eta_min=1e-6)\n",
    "hist_2 = get_lr_history(sched_2, opt_2, TOTAL_STEPS)\n",
    "\n",
    "# Case 3: Cosine Decay with Warmup\n",
    "model_3 = nn.Linear(D_MODEL, VOCAB_SIZE)\n",
    "opt_3 = optim.AdamW(model_3.parameters(), lr=lr)\n",
    "sched_3 = torch.optim.lr_scheduler.LambdaLR(opt_3, lr_lambda=get_cosine_with_warmup_lr_lambda(TOTAL_STEPS, WARMUP_STEPS, min_lr_ratio=2e-3))\n",
    "hist_3 = get_lr_history(sched_3, opt_3, TOTAL_STEPS)\n",
    "\n",
    "# 3. 가로로 3개 출력 (시각화)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "titles = ['LambdaLR (Warmup)', 'CosineAnnealingLR', 'Cosine with Warmup']\n",
    "histories = [hist_1, hist_2, hist_3]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(range(TOTAL_STEPS), histories[i], color=colors[i], linewidth=2)\n",
    "    ax.set_title(titles[i], fontsize=14)\n",
    "    ax.set_xlabel('Steps (Epochs)', fontsize=12)\n",
    "    ax.set_ylabel('Learning Rate', fontsize=12)\n",
    "    # ax.set_yscale('log')\n",
    "    # ax.set_ylim(1e-9, 2e-3)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cbc53f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW + 선형 워밍업\n",
    "optimizer = optim.AdamW(model.parameters(), lr = noam_lr, betas=(0.9, 0.98), weight_decay=0.01)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=WARMUP_STEPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AdamW + 코사인 어닐링\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.98), weight_decay=0.01)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=TOTAL_STEPS, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AdamW +  코사인 워밍업\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9,  weight_decay=0.01)\n",
    "# scheduler = lr_scheduler.LambdaLR(\n",
    "#     optimizer,\n",
    "#     lr_lambda=get_cosine_with_warmup_lr_lambda(\n",
    "#         total_steps=TOTAL_STEPS,\n",
    "#         warmup_steps=WARMUP_STEPS,\n",
    "#         min_lr_ratio=2e-3\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323792c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58dcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true: (batch_size, seq_len)|\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "    mask = (y_true != pad_id)\n",
    "    correct = (preds == y_true) & mask\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0476106",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3e772",
   "metadata": {},
   "source": [
    "훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 모델 포워드 패스\n",
    "    logits = model(enc_input, dec_input)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Loss 계산 (패딩 토큰 무시)\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)  # (batch_size, vocab_size, seq_len) 필요\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target, pad_id=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5131f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device, save_path=\"checkpoints\"):\n",
    "    model.to(device)\n",
    "\n",
    "    # best_avg_acc = 0\n",
    "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # 1. 저장 디렉토리 생성\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_function, device)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            # 학습률 스케줄러 업데이트\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")\n",
    "        \n",
    "        # --- 2. 10 에포크마다 체크포인트 저장 ---\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_file = os.path.join(save_path, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "            \n",
    "            # 모델 가중치, 옵티마이저, 스케줄러 상태를 모두 저장 (재개 가능하도록)\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, checkpoint_file)\n",
    "            \n",
    "            print(f\"==> Checkpoint saved: {checkpoint_file}\")\n",
    "        \n",
    "        # if avg_acc > best_avg_acc:\n",
    "        #     best_val_loss = avg_acc\n",
    "        #     best_epoch = epoch+1\n",
    "        #     best_model_wts = copy.deepcopy(model.state_dict()) \n",
    "\n",
    "        # print(f\"best{best_epoch}\")\n",
    "        # model.load_state_dict(best_model_wts)\n",
    "\n",
    "# checkpoint = torch.load('checkpoints/checkpoint_epoch_10.pt')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49, Step 600] Loss: 0.0268, Acc: 0.9958\n",
      "[Epoch 49, Step 700] Loss: 0.0302, Acc: 0.9966\n",
      "Epoch 49 Completed - Avg Loss: 0.0443, Avg Acc: 0.9909\n",
      "best49\n",
      "[Epoch 50, Step 0] Loss: 0.0191, Acc: 0.9963\n",
      "[Epoch 50, Step 100] Loss: 0.0618, Acc: 0.9883\n",
      "[Epoch 50, Step 200] Loss: 0.0454, Acc: 0.9894\n",
      "[Epoch 50, Step 300] Loss: 0.0137, Acc: 1.0000\n",
      "[Epoch 50, Step 400] Loss: 0.0515, Acc: 0.9898\n",
      "[Epoch 50, Step 500] Loss: 0.0270, Acc: 0.9923\n",
      "[Epoch 50, Step 600] Loss: 0.0630, Acc: 0.9926\n",
      "[Epoch 50, Step 700] Loss: 0.0900, Acc: 0.9822\n",
      "Epoch 50 Completed - Avg Loss: 0.0432, Avg Acc: 0.9916\n",
      "==> Checkpoint saved: checkpoints/checkpoint_epoch_50.pt\n",
      "best50\n",
      "[Epoch 51, Step 0] Loss: 0.0550, Acc: 0.9921\n",
      "[Epoch 51, Step 100] Loss: 0.0325, Acc: 0.9928\n",
      "[Epoch 51, Step 200] Loss: 0.0194, Acc: 1.0000\n",
      "[Epoch 51, Step 300] Loss: 0.0209, Acc: 0.9921\n",
      "[Epoch 51, Step 400] Loss: 0.0907, Acc: 0.9735\n",
      "[Epoch 51, Step 500] Loss: 0.0355, Acc: 0.9853\n",
      "[Epoch 51, Step 600] Loss: 0.0594, Acc: 0.9929\n",
      "[Epoch 51, Step 700] Loss: 0.0399, Acc: 0.9922\n",
      "Epoch 51 Completed - Avg Loss: 0.0418, Avg Acc: 0.9918\n",
      "best51\n",
      "[Epoch 52, Step 0] Loss: 0.0477, Acc: 0.9851\n",
      "[Epoch 52, Step 100] Loss: 0.0474, Acc: 0.9885\n",
      "[Epoch 52, Step 200] Loss: 0.0400, Acc: 0.9931\n",
      "[Epoch 52, Step 300] Loss: 0.0285, Acc: 0.9962\n",
      "[Epoch 52, Step 400] Loss: 0.0131, Acc: 1.0000\n",
      "[Epoch 52, Step 500] Loss: 0.0247, Acc: 0.9963\n",
      "[Epoch 52, Step 600] Loss: 0.0334, Acc: 0.9963\n",
      "[Epoch 52, Step 700] Loss: 0.0426, Acc: 0.9887\n",
      "Epoch 52 Completed - Avg Loss: 0.0394, Avg Acc: 0.9920\n",
      "best52\n",
      "[Epoch 53, Step 0] Loss: 0.0323, Acc: 0.9885\n",
      "[Epoch 53, Step 100] Loss: 0.0321, Acc: 0.9880\n",
      "[Epoch 53, Step 200] Loss: 0.0142, Acc: 1.0000\n",
      "[Epoch 53, Step 300] Loss: 0.0152, Acc: 0.9964\n",
      "[Epoch 53, Step 400] Loss: 0.0246, Acc: 0.9964\n",
      "[Epoch 53, Step 500] Loss: 0.0513, Acc: 0.9817\n",
      "[Epoch 53, Step 600] Loss: 0.0461, Acc: 0.9888\n",
      "[Epoch 53, Step 700] Loss: 0.0682, Acc: 0.9859\n",
      "Epoch 53 Completed - Avg Loss: 0.0366, Avg Acc: 0.9928\n",
      "best53\n",
      "[Epoch 54, Step 0] Loss: 0.0402, Acc: 0.9957\n",
      "[Epoch 54, Step 100] Loss: 0.0170, Acc: 1.0000\n",
      "[Epoch 54, Step 200] Loss: 0.0347, Acc: 0.9926\n",
      "[Epoch 54, Step 300] Loss: 0.0339, Acc: 0.9964\n",
      "[Epoch 54, Step 400] Loss: 0.0476, Acc: 0.9930\n",
      "[Epoch 54, Step 500] Loss: 0.0555, Acc: 0.9897\n",
      "[Epoch 54, Step 600] Loss: 0.0231, Acc: 0.9924\n",
      "[Epoch 54, Step 700] Loss: 0.0365, Acc: 0.9896\n",
      "Epoch 54 Completed - Avg Loss: 0.0376, Avg Acc: 0.9924\n",
      "best54\n",
      "[Epoch 55, Step 0] Loss: 0.0343, Acc: 0.9889\n",
      "[Epoch 55, Step 100] Loss: 0.0267, Acc: 0.9957\n",
      "[Epoch 55, Step 200] Loss: 0.0446, Acc: 0.9815\n",
      "[Epoch 55, Step 300] Loss: 0.0408, Acc: 0.9960\n",
      "[Epoch 55, Step 400] Loss: 0.0314, Acc: 0.9960\n",
      "[Epoch 55, Step 500] Loss: 0.0454, Acc: 0.9883\n",
      "[Epoch 55, Step 600] Loss: 0.0600, Acc: 0.9825\n",
      "[Epoch 55, Step 700] Loss: 0.0579, Acc: 0.9880\n",
      "Epoch 55 Completed - Avg Loss: 0.0355, Avg Acc: 0.9929\n",
      "best55\n",
      "[Epoch 56, Step 0] Loss: 0.0439, Acc: 0.9917\n",
      "[Epoch 56, Step 100] Loss: 0.0304, Acc: 0.9920\n",
      "[Epoch 56, Step 200] Loss: 0.0148, Acc: 0.9965\n",
      "[Epoch 56, Step 300] Loss: 0.0150, Acc: 1.0000\n",
      "[Epoch 56, Step 400] Loss: 0.0473, Acc: 0.9855\n",
      "[Epoch 56, Step 500] Loss: 0.0235, Acc: 0.9934\n",
      "[Epoch 56, Step 600] Loss: 0.0172, Acc: 1.0000\n",
      "[Epoch 56, Step 700] Loss: 0.0445, Acc: 0.9922\n",
      "Epoch 56 Completed - Avg Loss: 0.0340, Avg Acc: 0.9935\n",
      "best56\n",
      "[Epoch 57, Step 0] Loss: 0.0239, Acc: 0.9965\n",
      "[Epoch 57, Step 100] Loss: 0.0305, Acc: 0.9927\n",
      "[Epoch 57, Step 200] Loss: 0.0521, Acc: 0.9842\n",
      "[Epoch 57, Step 300] Loss: 0.0122, Acc: 1.0000\n",
      "[Epoch 57, Step 400] Loss: 0.0411, Acc: 0.9925\n",
      "[Epoch 57, Step 500] Loss: 0.0380, Acc: 0.9962\n",
      "[Epoch 57, Step 600] Loss: 0.1003, Acc: 0.9888\n",
      "[Epoch 57, Step 700] Loss: 0.0181, Acc: 1.0000\n",
      "Epoch 57 Completed - Avg Loss: 0.0330, Avg Acc: 0.9937\n",
      "best57\n",
      "[Epoch 58, Step 0] Loss: 0.0093, Acc: 0.9960\n",
      "[Epoch 58, Step 100] Loss: 0.0120, Acc: 1.0000\n",
      "[Epoch 58, Step 200] Loss: 0.0507, Acc: 0.9923\n",
      "[Epoch 58, Step 300] Loss: 0.0101, Acc: 1.0000\n",
      "[Epoch 58, Step 400] Loss: 0.0682, Acc: 0.9929\n",
      "[Epoch 58, Step 500] Loss: 0.0360, Acc: 0.9874\n",
      "[Epoch 58, Step 600] Loss: 0.0318, Acc: 0.9917\n",
      "[Epoch 58, Step 700] Loss: 0.0267, Acc: 0.9966\n",
      "Epoch 58 Completed - Avg Loss: 0.0316, Avg Acc: 0.9941\n",
      "best58\n",
      "[Epoch 59, Step 0] Loss: 0.0418, Acc: 0.9919\n",
      "[Epoch 59, Step 100] Loss: 0.0345, Acc: 0.9912\n",
      "[Epoch 59, Step 200] Loss: 0.0163, Acc: 1.0000\n",
      "[Epoch 59, Step 300] Loss: 0.0203, Acc: 0.9962\n",
      "[Epoch 59, Step 400] Loss: 0.0478, Acc: 0.9894\n",
      "[Epoch 59, Step 500] Loss: 0.0331, Acc: 0.9962\n",
      "[Epoch 59, Step 600] Loss: 0.0334, Acc: 0.9925\n",
      "[Epoch 59, Step 700] Loss: 0.0805, Acc: 0.9882\n",
      "Epoch 59 Completed - Avg Loss: 0.0318, Avg Acc: 0.9939\n",
      "best59\n",
      "[Epoch 60, Step 0] Loss: 0.0067, Acc: 1.0000\n",
      "[Epoch 60, Step 100] Loss: 0.0434, Acc: 0.9844\n",
      "[Epoch 60, Step 200] Loss: 0.0481, Acc: 0.9768\n",
      "[Epoch 60, Step 300] Loss: 0.0181, Acc: 1.0000\n",
      "[Epoch 60, Step 400] Loss: 0.0304, Acc: 1.0000\n",
      "[Epoch 60, Step 500] Loss: 0.0313, Acc: 0.9964\n",
      "[Epoch 60, Step 600] Loss: 0.0249, Acc: 0.9930\n",
      "[Epoch 60, Step 700] Loss: 0.0210, Acc: 0.9932\n",
      "Epoch 60 Completed - Avg Loss: 0.0315, Avg Acc: 0.9939\n",
      "==> Checkpoint saved: checkpoints/checkpoint_epoch_60.pt\n",
      "best60\n",
      "[Epoch 61, Step 0] Loss: 0.0112, Acc: 1.0000\n",
      "[Epoch 61, Step 100] Loss: 0.0053, Acc: 1.0000\n",
      "[Epoch 61, Step 200] Loss: 0.0146, Acc: 0.9966\n",
      "[Epoch 61, Step 300] Loss: 0.0086, Acc: 1.0000\n",
      "[Epoch 61, Step 400] Loss: 0.1104, Acc: 0.9748\n",
      "[Epoch 61, Step 500] Loss: 0.0298, Acc: 0.9886\n",
      "[Epoch 61, Step 600] Loss: 0.0106, Acc: 1.0000\n",
      "[Epoch 61, Step 700] Loss: 0.0368, Acc: 0.9928\n",
      "Epoch 61 Completed - Avg Loss: 0.0298, Avg Acc: 0.9942\n",
      "best61\n",
      "[Epoch 62, Step 0] Loss: 0.0088, Acc: 1.0000\n",
      "[Epoch 62, Step 100] Loss: 0.0654, Acc: 0.9888\n",
      "[Epoch 62, Step 200] Loss: 0.0126, Acc: 0.9965\n",
      "[Epoch 62, Step 300] Loss: 0.0118, Acc: 1.0000\n",
      "[Epoch 62, Step 400] Loss: 0.0125, Acc: 0.9960\n",
      "[Epoch 62, Step 500] Loss: 0.0283, Acc: 1.0000\n",
      "[Epoch 62, Step 600] Loss: 0.0241, Acc: 0.9933\n",
      "[Epoch 62, Step 700] Loss: 0.0687, Acc: 0.9887\n",
      "Epoch 62 Completed - Avg Loss: 0.0292, Avg Acc: 0.9944\n",
      "best62\n",
      "[Epoch 63, Step 0] Loss: 0.0310, Acc: 0.9965\n",
      "[Epoch 63, Step 100] Loss: 0.0127, Acc: 0.9964\n",
      "[Epoch 63, Step 200] Loss: 0.0434, Acc: 0.9896\n",
      "[Epoch 63, Step 300] Loss: 0.0147, Acc: 0.9966\n",
      "[Epoch 63, Step 400] Loss: 0.0370, Acc: 0.9962\n",
      "[Epoch 63, Step 500] Loss: 0.0110, Acc: 1.0000\n",
      "[Epoch 63, Step 600] Loss: 0.0188, Acc: 0.9961\n",
      "[Epoch 63, Step 700] Loss: 0.0160, Acc: 1.0000\n",
      "Epoch 63 Completed - Avg Loss: 0.0279, Avg Acc: 0.9945\n",
      "best63\n",
      "[Epoch 64, Step 0] Loss: 0.0717, Acc: 0.9851\n",
      "[Epoch 64, Step 100] Loss: 0.0154, Acc: 0.9930\n",
      "[Epoch 64, Step 200] Loss: 0.0145, Acc: 1.0000\n",
      "[Epoch 64, Step 300] Loss: 0.0246, Acc: 0.9966\n",
      "[Epoch 64, Step 400] Loss: 0.0191, Acc: 1.0000\n",
      "[Epoch 64, Step 500] Loss: 0.0249, Acc: 0.9886\n",
      "[Epoch 64, Step 600] Loss: 0.0400, Acc: 0.9842\n",
      "[Epoch 64, Step 700] Loss: 0.0134, Acc: 1.0000\n",
      "Epoch 64 Completed - Avg Loss: 0.0276, Avg Acc: 0.9948\n",
      "best64\n",
      "[Epoch 65, Step 0] Loss: 0.0308, Acc: 0.9933\n",
      "[Epoch 65, Step 100] Loss: 0.0108, Acc: 1.0000\n",
      "[Epoch 65, Step 200] Loss: 0.0328, Acc: 0.9924\n",
      "[Epoch 65, Step 300] Loss: 0.0379, Acc: 0.9925\n",
      "[Epoch 65, Step 400] Loss: 0.0075, Acc: 1.0000\n",
      "[Epoch 65, Step 500] Loss: 0.0516, Acc: 0.9962\n",
      "[Epoch 65, Step 600] Loss: 0.0270, Acc: 0.9923\n",
      "[Epoch 65, Step 700] Loss: 0.0305, Acc: 0.9964\n",
      "Epoch 65 Completed - Avg Loss: 0.0262, Avg Acc: 0.9947\n",
      "best65\n",
      "[Epoch 66, Step 0] Loss: 0.0104, Acc: 1.0000\n",
      "[Epoch 66, Step 100] Loss: 0.0428, Acc: 0.9879\n",
      "[Epoch 66, Step 200] Loss: 0.0110, Acc: 0.9959\n",
      "[Epoch 66, Step 300] Loss: 0.0169, Acc: 0.9964\n",
      "[Epoch 66, Step 400] Loss: 0.0197, Acc: 0.9965\n",
      "[Epoch 66, Step 500] Loss: 0.0300, Acc: 0.9919\n",
      "[Epoch 66, Step 600] Loss: 0.0364, Acc: 0.9858\n",
      "[Epoch 66, Step 700] Loss: 0.0251, Acc: 0.9962\n",
      "Epoch 66 Completed - Avg Loss: 0.0278, Avg Acc: 0.9946\n",
      "best66\n",
      "[Epoch 67, Step 0] Loss: 0.0132, Acc: 0.9961\n",
      "[Epoch 67, Step 100] Loss: 0.0066, Acc: 1.0000\n",
      "[Epoch 67, Step 200] Loss: 0.0210, Acc: 0.9921\n",
      "[Epoch 67, Step 300] Loss: 0.0308, Acc: 0.9880\n",
      "[Epoch 67, Step 400] Loss: 0.0393, Acc: 0.9964\n",
      "[Epoch 67, Step 500] Loss: 0.0085, Acc: 1.0000\n",
      "[Epoch 67, Step 600] Loss: 0.0235, Acc: 0.9919\n",
      "[Epoch 67, Step 700] Loss: 0.0089, Acc: 1.0000\n",
      "Epoch 67 Completed - Avg Loss: 0.0244, Avg Acc: 0.9954\n",
      "best67\n",
      "[Epoch 68, Step 0] Loss: 0.0417, Acc: 0.9919\n",
      "[Epoch 68, Step 100] Loss: 0.0073, Acc: 1.0000\n",
      "[Epoch 68, Step 200] Loss: 0.0102, Acc: 1.0000\n",
      "[Epoch 68, Step 300] Loss: 0.0219, Acc: 0.9962\n",
      "[Epoch 68, Step 400] Loss: 0.0081, Acc: 1.0000\n",
      "[Epoch 68, Step 500] Loss: 0.0120, Acc: 1.0000\n",
      "[Epoch 68, Step 600] Loss: 0.0377, Acc: 0.9921\n",
      "[Epoch 68, Step 700] Loss: 0.0403, Acc: 0.9925\n",
      "Epoch 68 Completed - Avg Loss: 0.0246, Avg Acc: 0.9953\n",
      "best68\n",
      "[Epoch 69, Step 0] Loss: 0.0072, Acc: 1.0000\n",
      "[Epoch 69, Step 100] Loss: 0.0276, Acc: 0.9889\n",
      "[Epoch 69, Step 200] Loss: 0.0218, Acc: 0.9928\n",
      "[Epoch 69, Step 300] Loss: 0.0155, Acc: 0.9962\n",
      "[Epoch 69, Step 400] Loss: 0.0186, Acc: 0.9920\n",
      "[Epoch 69, Step 500] Loss: 0.0374, Acc: 0.9924\n",
      "[Epoch 69, Step 600] Loss: 0.0180, Acc: 0.9963\n",
      "[Epoch 69, Step 700] Loss: 0.0246, Acc: 0.9933\n",
      "Epoch 69 Completed - Avg Loss: 0.0246, Avg Acc: 0.9953\n",
      "best69\n",
      "[Epoch 70, Step 0] Loss: 0.0074, Acc: 1.0000\n",
      "[Epoch 70, Step 100] Loss: 0.0071, Acc: 1.0000\n",
      "[Epoch 70, Step 200] Loss: 0.0102, Acc: 0.9962\n",
      "[Epoch 70, Step 300] Loss: 0.0140, Acc: 1.0000\n",
      "[Epoch 70, Step 400] Loss: 0.0331, Acc: 0.9964\n",
      "[Epoch 70, Step 500] Loss: 0.0316, Acc: 0.9931\n",
      "[Epoch 70, Step 600] Loss: 0.0247, Acc: 0.9929\n",
      "[Epoch 70, Step 700] Loss: 0.0276, Acc: 0.9965\n",
      "Epoch 70 Completed - Avg Loss: 0.0231, Avg Acc: 0.9956\n",
      "==> Checkpoint saved: checkpoints/checkpoint_epoch_70.pt\n",
      "best70\n",
      "[Epoch 71, Step 0] Loss: 0.0120, Acc: 1.0000\n",
      "[Epoch 71, Step 100] Loss: 0.0085, Acc: 1.0000\n",
      "[Epoch 71, Step 200] Loss: 0.0268, Acc: 0.9889\n",
      "[Epoch 71, Step 300] Loss: 0.0127, Acc: 0.9960\n",
      "[Epoch 71, Step 400] Loss: 0.0510, Acc: 0.9925\n",
      "[Epoch 71, Step 500] Loss: 0.0119, Acc: 1.0000\n",
      "[Epoch 71, Step 600] Loss: 0.0119, Acc: 0.9958\n",
      "[Epoch 71, Step 700] Loss: 0.0323, Acc: 0.9847\n",
      "Epoch 71 Completed - Avg Loss: 0.0235, Avg Acc: 0.9954\n",
      "best71\n",
      "[Epoch 72, Step 0] Loss: 0.0269, Acc: 0.9902\n",
      "[Epoch 72, Step 100] Loss: 0.0072, Acc: 1.0000\n",
      "[Epoch 72, Step 200] Loss: 0.0100, Acc: 1.0000\n",
      "[Epoch 72, Step 300] Loss: 0.0553, Acc: 0.9891\n",
      "[Epoch 72, Step 400] Loss: 0.0462, Acc: 0.9918\n",
      "[Epoch 72, Step 500] Loss: 0.0372, Acc: 0.9868\n",
      "[Epoch 72, Step 600] Loss: 0.0450, Acc: 0.9958\n",
      "[Epoch 72, Step 700] Loss: 0.0441, Acc: 0.9878\n",
      "Epoch 72 Completed - Avg Loss: 0.0231, Avg Acc: 0.9956\n",
      "best72\n",
      "[Epoch 73, Step 0] Loss: 0.0321, Acc: 0.9916\n",
      "[Epoch 73, Step 100] Loss: 0.0232, Acc: 0.9931\n",
      "[Epoch 73, Step 200] Loss: 0.0195, Acc: 0.9923\n",
      "[Epoch 73, Step 300] Loss: 0.0262, Acc: 0.9922\n",
      "[Epoch 73, Step 400] Loss: 0.0073, Acc: 1.0000\n",
      "[Epoch 73, Step 500] Loss: 0.0510, Acc: 0.9927\n",
      "[Epoch 73, Step 600] Loss: 0.0758, Acc: 0.9957\n",
      "[Epoch 73, Step 700] Loss: 0.0127, Acc: 1.0000\n",
      "Epoch 73 Completed - Avg Loss: 0.0229, Avg Acc: 0.9956\n",
      "best73\n",
      "[Epoch 74, Step 0] Loss: 0.0672, Acc: 0.9797\n",
      "[Epoch 74, Step 100] Loss: 0.0100, Acc: 1.0000\n",
      "[Epoch 74, Step 200] Loss: 0.0591, Acc: 0.9894\n",
      "[Epoch 74, Step 300] Loss: 0.0238, Acc: 0.9966\n",
      "[Epoch 74, Step 400] Loss: 0.0081, Acc: 1.0000\n",
      "[Epoch 74, Step 500] Loss: 0.0124, Acc: 0.9961\n",
      "[Epoch 74, Step 600] Loss: 0.0210, Acc: 0.9965\n",
      "[Epoch 74, Step 700] Loss: 0.0257, Acc: 0.9962\n",
      "Epoch 74 Completed - Avg Loss: 0.0225, Avg Acc: 0.9956\n",
      "best74\n",
      "[Epoch 75, Step 0] Loss: 0.0069, Acc: 1.0000\n",
      "[Epoch 75, Step 100] Loss: 0.0109, Acc: 1.0000\n",
      "[Epoch 75, Step 200] Loss: 0.0526, Acc: 0.9961\n",
      "[Epoch 75, Step 300] Loss: 0.0100, Acc: 1.0000\n",
      "[Epoch 75, Step 400] Loss: 0.0545, Acc: 0.9874\n",
      "[Epoch 75, Step 500] Loss: 0.0223, Acc: 0.9931\n",
      "[Epoch 75, Step 600] Loss: 0.0199, Acc: 0.9921\n",
      "[Epoch 75, Step 700] Loss: 0.0161, Acc: 0.9962\n",
      "Epoch 75 Completed - Avg Loss: 0.0214, Avg Acc: 0.9959\n",
      "best75\n",
      "[Epoch 76, Step 0] Loss: 0.0592, Acc: 0.9913\n",
      "[Epoch 76, Step 100] Loss: 0.0084, Acc: 1.0000\n",
      "[Epoch 76, Step 200] Loss: 0.0126, Acc: 1.0000\n",
      "[Epoch 76, Step 300] Loss: 0.0292, Acc: 0.9925\n",
      "[Epoch 76, Step 400] Loss: 0.0176, Acc: 1.0000\n",
      "[Epoch 76, Step 500] Loss: 0.0396, Acc: 0.9917\n",
      "[Epoch 76, Step 600] Loss: 0.0262, Acc: 0.9922\n",
      "[Epoch 76, Step 700] Loss: 0.0345, Acc: 0.9894\n",
      "Epoch 76 Completed - Avg Loss: 0.0204, Avg Acc: 0.9961\n",
      "best76\n",
      "[Epoch 77, Step 0] Loss: 0.0122, Acc: 0.9963\n",
      "[Epoch 77, Step 100] Loss: 0.0052, Acc: 1.0000\n",
      "[Epoch 77, Step 200] Loss: 0.0051, Acc: 1.0000\n",
      "[Epoch 77, Step 300] Loss: 0.0124, Acc: 0.9915\n",
      "[Epoch 77, Step 400] Loss: 0.0099, Acc: 1.0000\n",
      "[Epoch 77, Step 500] Loss: 0.1029, Acc: 0.9835\n",
      "[Epoch 77, Step 600] Loss: 0.0057, Acc: 1.0000\n",
      "[Epoch 77, Step 700] Loss: 0.0249, Acc: 0.9964\n",
      "Epoch 77 Completed - Avg Loss: 0.0207, Avg Acc: 0.9960\n",
      "best77\n",
      "[Epoch 78, Step 0] Loss: 0.0271, Acc: 0.9892\n",
      "[Epoch 78, Step 100] Loss: 0.0172, Acc: 0.9960\n",
      "[Epoch 78, Step 200] Loss: 0.0323, Acc: 0.9921\n",
      "[Epoch 78, Step 300] Loss: 0.0418, Acc: 0.9961\n",
      "[Epoch 78, Step 400] Loss: 0.0264, Acc: 0.9881\n",
      "[Epoch 78, Step 500] Loss: 0.0205, Acc: 0.9927\n",
      "[Epoch 78, Step 600] Loss: 0.0070, Acc: 1.0000\n",
      "[Epoch 78, Step 700] Loss: 0.0213, Acc: 0.9923\n",
      "Epoch 78 Completed - Avg Loss: 0.0193, Avg Acc: 0.9962\n",
      "best78\n",
      "[Epoch 79, Step 0] Loss: 0.0185, Acc: 0.9958\n",
      "[Epoch 79, Step 100] Loss: 0.0169, Acc: 0.9929\n",
      "[Epoch 79, Step 200] Loss: 0.0122, Acc: 1.0000\n",
      "[Epoch 79, Step 300] Loss: 0.0084, Acc: 1.0000\n",
      "[Epoch 79, Step 400] Loss: 0.0125, Acc: 1.0000\n",
      "[Epoch 79, Step 500] Loss: 0.0144, Acc: 1.0000\n",
      "[Epoch 79, Step 600] Loss: 0.0096, Acc: 1.0000\n",
      "[Epoch 79, Step 700] Loss: 0.0173, Acc: 0.9962\n",
      "Epoch 79 Completed - Avg Loss: 0.0193, Avg Acc: 0.9963\n",
      "best79\n",
      "[Epoch 80, Step 0] Loss: 0.0200, Acc: 0.9961\n",
      "[Epoch 80, Step 100] Loss: 0.0049, Acc: 1.0000\n",
      "[Epoch 80, Step 200] Loss: 0.0320, Acc: 0.9883\n",
      "[Epoch 80, Step 300] Loss: 0.0046, Acc: 1.0000\n",
      "[Epoch 80, Step 400] Loss: 0.0264, Acc: 0.9924\n",
      "[Epoch 80, Step 500] Loss: 0.0201, Acc: 0.9961\n",
      "[Epoch 80, Step 600] Loss: 0.0267, Acc: 0.9922\n",
      "[Epoch 80, Step 700] Loss: 0.0071, Acc: 1.0000\n",
      "Epoch 80 Completed - Avg Loss: 0.0186, Avg Acc: 0.9964\n",
      "==> Checkpoint saved: checkpoints/checkpoint_epoch_80.pt\n",
      "best80\n",
      "[Epoch 81, Step 0] Loss: 0.0318, Acc: 0.9884\n",
      "[Epoch 81, Step 100] Loss: 0.0091, Acc: 1.0000\n",
      "[Epoch 81, Step 200] Loss: 0.0096, Acc: 0.9967\n",
      "[Epoch 81, Step 300] Loss: 0.0056, Acc: 1.0000\n",
      "[Epoch 81, Step 400] Loss: 0.0169, Acc: 0.9960\n",
      "[Epoch 81, Step 500] Loss: 0.0117, Acc: 0.9961\n",
      "[Epoch 81, Step 600] Loss: 0.0477, Acc: 0.9925\n",
      "[Epoch 81, Step 700] Loss: 0.0146, Acc: 1.0000\n",
      "Epoch 81 Completed - Avg Loss: 0.0187, Avg Acc: 0.9964\n",
      "best81\n",
      "[Epoch 82, Step 0] Loss: 0.0131, Acc: 0.9956\n",
      "[Epoch 82, Step 100] Loss: 0.0686, Acc: 0.9964\n",
      "[Epoch 82, Step 200] Loss: 0.0063, Acc: 1.0000\n",
      "[Epoch 82, Step 300] Loss: 0.0040, Acc: 1.0000\n",
      "[Epoch 82, Step 400] Loss: 0.0069, Acc: 1.0000\n",
      "[Epoch 82, Step 500] Loss: 0.0133, Acc: 0.9916\n",
      "[Epoch 82, Step 600] Loss: 0.0265, Acc: 0.9958\n",
      "[Epoch 82, Step 700] Loss: 0.0120, Acc: 1.0000\n",
      "Epoch 82 Completed - Avg Loss: 0.0188, Avg Acc: 0.9965\n",
      "best82\n",
      "[Epoch 83, Step 0] Loss: 0.0124, Acc: 0.9960\n",
      "[Epoch 83, Step 100] Loss: 0.0069, Acc: 1.0000\n",
      "[Epoch 83, Step 200] Loss: 0.0116, Acc: 0.9919\n",
      "[Epoch 83, Step 300] Loss: 0.0186, Acc: 0.9963\n",
      "[Epoch 83, Step 400] Loss: 0.0310, Acc: 0.9961\n",
      "[Epoch 83, Step 500] Loss: 0.0103, Acc: 1.0000\n",
      "[Epoch 83, Step 600] Loss: 0.0066, Acc: 1.0000\n",
      "[Epoch 83, Step 700] Loss: 0.0370, Acc: 0.9923\n",
      "Epoch 83 Completed - Avg Loss: 0.0179, Avg Acc: 0.9966\n",
      "best83\n",
      "[Epoch 84, Step 0] Loss: 0.0087, Acc: 0.9962\n",
      "[Epoch 84, Step 100] Loss: 0.0127, Acc: 0.9960\n",
      "[Epoch 84, Step 200] Loss: 0.0082, Acc: 1.0000\n",
      "[Epoch 84, Step 300] Loss: 0.0103, Acc: 1.0000\n",
      "[Epoch 84, Step 400] Loss: 0.0060, Acc: 1.0000\n",
      "[Epoch 84, Step 500] Loss: 0.0121, Acc: 1.0000\n",
      "[Epoch 84, Step 600] Loss: 0.0048, Acc: 1.0000\n",
      "[Epoch 84, Step 700] Loss: 0.0035, Acc: 1.0000\n",
      "Epoch 84 Completed - Avg Loss: 0.0173, Avg Acc: 0.9968\n",
      "best84\n",
      "[Epoch 85, Step 0] Loss: 0.0134, Acc: 0.9923\n",
      "[Epoch 85, Step 100] Loss: 0.0037, Acc: 1.0000\n",
      "[Epoch 85, Step 200] Loss: 0.0205, Acc: 0.9962\n",
      "[Epoch 85, Step 300] Loss: 0.0106, Acc: 1.0000\n",
      "[Epoch 85, Step 400] Loss: 0.0069, Acc: 1.0000\n",
      "[Epoch 85, Step 500] Loss: 0.0115, Acc: 0.9961\n",
      "[Epoch 85, Step 600] Loss: 0.0159, Acc: 1.0000\n",
      "[Epoch 85, Step 700] Loss: 0.0696, Acc: 0.9896\n",
      "Epoch 85 Completed - Avg Loss: 0.0173, Avg Acc: 0.9966\n",
      "best85\n",
      "[Epoch 86, Step 0] Loss: 0.0040, Acc: 1.0000\n",
      "[Epoch 86, Step 100] Loss: 0.0613, Acc: 0.9897\n",
      "[Epoch 86, Step 200] Loss: 0.0059, Acc: 1.0000\n",
      "[Epoch 86, Step 300] Loss: 0.0131, Acc: 0.9961\n",
      "[Epoch 86, Step 400] Loss: 0.0348, Acc: 0.9891\n",
      "[Epoch 86, Step 500] Loss: 0.0214, Acc: 1.0000\n",
      "[Epoch 86, Step 600] Loss: 0.0032, Acc: 1.0000\n",
      "[Epoch 86, Step 700] Loss: 0.0044, Acc: 1.0000\n",
      "Epoch 86 Completed - Avg Loss: 0.0166, Avg Acc: 0.9967\n",
      "best86\n",
      "[Epoch 87, Step 0] Loss: 0.0046, Acc: 1.0000\n",
      "[Epoch 87, Step 100] Loss: 0.0172, Acc: 0.9960\n",
      "[Epoch 87, Step 200] Loss: 0.0069, Acc: 1.0000\n",
      "[Epoch 87, Step 300] Loss: 0.0474, Acc: 0.9958\n",
      "[Epoch 87, Step 400] Loss: 0.0172, Acc: 0.9967\n",
      "[Epoch 87, Step 500] Loss: 0.0064, Acc: 1.0000\n",
      "[Epoch 87, Step 600] Loss: 0.0351, Acc: 0.9961\n",
      "[Epoch 87, Step 700] Loss: 0.0144, Acc: 1.0000\n",
      "Epoch 87 Completed - Avg Loss: 0.0174, Avg Acc: 0.9969\n",
      "best87\n",
      "[Epoch 88, Step 0] Loss: 0.0036, Acc: 1.0000\n",
      "[Epoch 88, Step 100] Loss: 0.0068, Acc: 1.0000\n",
      "[Epoch 88, Step 200] Loss: 0.0020, Acc: 1.0000\n",
      "[Epoch 88, Step 300] Loss: 0.0096, Acc: 0.9961\n",
      "[Epoch 88, Step 400] Loss: 0.0294, Acc: 0.9963\n",
      "[Epoch 88, Step 500] Loss: 0.0098, Acc: 1.0000\n",
      "[Epoch 88, Step 600] Loss: 0.0048, Acc: 1.0000\n",
      "[Epoch 88, Step 700] Loss: 0.0073, Acc: 1.0000\n",
      "Epoch 88 Completed - Avg Loss: 0.0162, Avg Acc: 0.9969\n",
      "best88\n",
      "[Epoch 89, Step 0] Loss: 0.0066, Acc: 0.9963\n",
      "[Epoch 89, Step 100] Loss: 0.0100, Acc: 0.9959\n",
      "[Epoch 89, Step 200] Loss: 0.0053, Acc: 1.0000\n",
      "[Epoch 89, Step 300] Loss: 0.0106, Acc: 0.9963\n",
      "[Epoch 89, Step 400] Loss: 0.0112, Acc: 0.9960\n",
      "[Epoch 89, Step 500] Loss: 0.0110, Acc: 0.9965\n",
      "[Epoch 89, Step 600] Loss: 0.0072, Acc: 1.0000\n",
      "[Epoch 89, Step 700] Loss: 0.0331, Acc: 0.9929\n",
      "Epoch 89 Completed - Avg Loss: 0.0160, Avg Acc: 0.9970\n",
      "best89\n",
      "[Epoch 90, Step 0] Loss: 0.0251, Acc: 0.9918\n",
      "[Epoch 90, Step 100] Loss: 0.0414, Acc: 0.9964\n",
      "[Epoch 90, Step 200] Loss: 0.0043, Acc: 1.0000\n",
      "[Epoch 90, Step 300] Loss: 0.0093, Acc: 0.9962\n",
      "[Epoch 90, Step 400] Loss: 0.0074, Acc: 1.0000\n",
      "[Epoch 90, Step 500] Loss: 0.0120, Acc: 1.0000\n",
      "[Epoch 90, Step 600] Loss: 0.0140, Acc: 0.9959\n",
      "[Epoch 90, Step 700] Loss: 0.0078, Acc: 1.0000\n",
      "Epoch 90 Completed - Avg Loss: 0.0162, Avg Acc: 0.9968\n",
      "==> Checkpoint saved: checkpoints/checkpoint_epoch_90.pt\n",
      "best90\n",
      "[Epoch 91, Step 0] Loss: 0.0026, Acc: 1.0000\n",
      "[Epoch 91, Step 100] Loss: 0.0226, Acc: 0.9964\n",
      "[Epoch 91, Step 200] Loss: 0.0035, Acc: 1.0000\n",
      "[Epoch 91, Step 300] Loss: 0.0171, Acc: 0.9961\n",
      "[Epoch 91, Step 400] Loss: 0.0078, Acc: 1.0000\n",
      "[Epoch 91, Step 500] Loss: 0.0131, Acc: 0.9959\n",
      "[Epoch 91, Step 600] Loss: 0.0234, Acc: 0.9922\n",
      "[Epoch 91, Step 700] Loss: 0.0054, Acc: 1.0000\n",
      "Epoch 91 Completed - Avg Loss: 0.0150, Avg Acc: 0.9971\n",
      "best91\n",
      "[Epoch 92, Step 0] Loss: 0.0371, Acc: 0.9918\n",
      "[Epoch 92, Step 100] Loss: 0.0068, Acc: 1.0000\n",
      "[Epoch 92, Step 200] Loss: 0.0196, Acc: 0.9962\n",
      "[Epoch 92, Step 300] Loss: 0.0162, Acc: 0.9963\n",
      "[Epoch 92, Step 400] Loss: 0.0095, Acc: 1.0000\n",
      "[Epoch 92, Step 500] Loss: 0.0106, Acc: 1.0000\n",
      "[Epoch 92, Step 600] Loss: 0.0057, Acc: 1.0000\n",
      "[Epoch 92, Step 700] Loss: 0.0067, Acc: 1.0000\n",
      "Epoch 92 Completed - Avg Loss: 0.0153, Avg Acc: 0.9970\n",
      "best92\n",
      "[Epoch 93, Step 0] Loss: 0.0177, Acc: 0.9960\n",
      "[Epoch 93, Step 100] Loss: 0.0050, Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=EPOCH,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e1ffb4",
   "metadata": {},
   "source": [
    "---\n",
    "#### 챗봇 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cpu'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN = tokenizer.eos_id()\n",
    "    MAX_LENGTH = 40\n",
    "\n",
    "    # 전처리\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 인코더 입력: [START] + 인코딩 + [END]\n",
    "    enc_input_ids = [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    # 차원 확장: (batch_size=1, seq_len)\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # 디코더 입력(dec_input)을 START_TOKEN만 포함한 상태로 시작\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()  # 모델 평가 모드\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # 모델 forward: (enc_input, dec_input) -> (batch_size=1, seq_len, vocab_size)\n",
    "            logits = model(enc_input, dec_input)\n",
    "\n",
    "            # 마지막 타임스텝의 예측만 추출: shape (1, 1, vocab_size)\n",
    "            # logits[:, -1, :] -> (1, vocab_size)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "\n",
    "            # argmax로 가장 높은 확률의 토큰 선택\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)  # shape: (1,)\n",
    "\n",
    "            # 종료 토큰이면 중단\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            # 디코더 입력(dec_input)에 예측 토큰을 이어붙임\n",
    "            predicted_id = predicted_id.unsqueeze(0)  # shape (1,1)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)\n",
    "\n",
    "    # 최종 시퀀스: dec_input: (1, seq_len)에서 (seq_len,)로\n",
    "    output_sequence = dec_input.squeeze(0).tolist()  # e.g. [START_TOKEN, ..., 토큰들...]\n",
    "\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29eed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cpu'):\n",
    "    # 디코더 인퍼런스 -> 예측된 토큰 시퀀스\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 토크나이저로 디코딩 (패딩, START/END 토큰 등은 제외하거나 처리)\n",
    "    # 여기서는 단순히 tokenizer.decode() 직접 호출\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a65da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '안녕'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '너 괜찮아'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"요즘 살이 찐 거 같은데 운동이나 해볼까?\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851be4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"요즘 살이 찐 거 같은데\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b59ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '바보야'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '멍청아'\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"너는 누구야?\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"사랑해\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ee6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"오늘 날씨 어때?\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"뭘까\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
